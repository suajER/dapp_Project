{"ast":null,"code":"'use strict';\n\nObject.defineProperty(exports, '__esModule', {\n  value: true\n});\n\nvar common = require('./common.js');\n\nvar token = require('./token.js');\n\nvar jump = require('./jump.js');\n\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\n\nclass Tokeniser {\n  constructor(data, options = {}) {\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n\n  done() {\n    return this.pos >= this.data.length;\n  }\n\n  next() {\n    const byt = this.data[this.pos];\n    let token = jump.quick[byt];\n\n    if (token === undefined) {\n      const decoder = jump.jump[byt];\n\n      if (!decoder) {\n        throw new Error(\"\".concat(common.decodeErrPrefix, \" no decoder for major type \").concat(byt >>> 5, \" (byte 0x\").concat(byt.toString(16).padStart(2, '0'), \")\"));\n      }\n\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n\n    this.pos += token.encodedLength;\n    return token;\n  }\n\n}\n\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\n\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" got unexpected break to lengthed array\"));\n    }\n\n    if (value === DONE) {\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" found array but not enough entries (got \").concat(i, \", expected \").concat(token.value, \")\"));\n    }\n\n    arr[i] = value;\n  }\n\n  return arr;\n}\n\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" got unexpected break to lengthed map\"));\n    }\n\n    if (key === DONE) {\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" found map but not enough entries (got \").concat(i, \" [no key], expected \").concat(token.value, \")\"));\n    }\n\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" non-string keys not supported (got \").concat(typeof key, \")\"));\n    }\n\n    const value = tokensToObject(tokeniser, options);\n\n    if (value === DONE) {\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" found map but not enough entries (got \").concat(i, \" [no value], expected \").concat(token.value, \")\"));\n    }\n\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n\n  return useMaps ? m : obj;\n}\n\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n\n  const token$1 = tokeniser.next();\n\n  if (token$1.type === token.Type.break) {\n    return BREAK;\n  }\n\n  if (token$1.type.terminal) {\n    return token$1.value;\n  }\n\n  if (token$1.type === token.Type.array) {\n    return tokenToArray(token$1, tokeniser, options);\n  }\n\n  if (token$1.type === token.Type.map) {\n    return tokenToMap(token$1, tokeniser, options);\n  }\n\n  if (token$1.type === token.Type.tag) {\n    if (options.tags && typeof options.tags[token$1.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token$1.value](tagged);\n    }\n\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" tag not supported (\").concat(token$1.value, \")\"));\n  }\n\n  throw new Error('unsupported');\n}\n\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" data to decode must be a Uint8Array\"));\n  }\n\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n\n  if (decoded === DONE) {\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" did not find any content to decode\"));\n  }\n\n  if (decoded === BREAK) {\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" got unexpected break\"));\n  }\n\n  if (!tokeniser.done()) {\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" too many terminals, data makes no sense\"));\n  }\n\n  return decoded;\n}\n\nexports.Tokeniser = Tokeniser;\nexports.decode = decode;\nexports.tokensToObject = tokensToObject;","map":null,"metadata":{},"sourceType":"script"}